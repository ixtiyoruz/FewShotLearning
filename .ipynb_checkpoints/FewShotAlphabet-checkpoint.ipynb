{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prototypical Networks for Few-shot Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the idea is to solve the problem of few shot learning in terms of classifier.\n",
    "- Classifier must generalize to new classes not seen in the training set, given only a small number of examples of each new class. \n",
    "- So, we don't give the model totally new dataset it will be given only a small number of them.\n",
    "Humans are well suited at this task, given one image we can learn what it is and classify the object.\n",
    "Prototypical networks learn a metric space in which classification can be performed by computing distances to prototype representations of each class.\n",
    "- What is prototype representation of a class ?\n",
    "    - I bet this paper is all about this, we have to read more \n",
    "- Their assumptions:\n",
    "    - Our approach, prototypical networks, is based on the idea that there exists an embedding in which points cluster around a single prototype representation for each class.\n",
    "- They learn an embedding of the meta-data into a shared space to serve as the prototype for each class.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, sys\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "import pandas as pd\n",
    "from threading import Thread\n",
    "from scipy import ndimage\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#Check GPU support, please do activate GPU\n",
    "print(torch.cuda.is_available())\n",
    "ctx = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_alphabets(alphabet_directory_path, alphabet_directory_name):\n",
    "    \"\"\"\n",
    "    Reads all the characters from a given alphabet_directory\n",
    "    \"\"\"\n",
    "    datax = []\n",
    "    datay = []\n",
    "    characters = os.listdir(alphabet_directory_path)\n",
    "    for character in characters:\n",
    "        images = os.listdir(alphabet_directory_path + character + '/')\n",
    "        for img in images:\n",
    "            image = cv2.resize(\n",
    "                cv2.imread(alphabet_directory_path + character + '/' + img),\n",
    "                (28,28)\n",
    "                )\n",
    "            #rotations of image\n",
    "            rotated_90 = ndimage.rotate(image, 90)\n",
    "            rotated_180 = ndimage.rotate(image, 180)\n",
    "            rotated_270 = ndimage.rotate(image, 270)\n",
    "            datax.extend((image, rotated_90, rotated_180, rotated_270))\n",
    "            datay.extend((\n",
    "                alphabet_directory_name + '_' + character + '_0',\n",
    "                alphabet_directory_name + '_' + character + '_90',\n",
    "                alphabet_directory_name + '_' + character + '_180',\n",
    "                alphabet_directory_name + '_' + character + '_270'\n",
    "            ))\n",
    "    return np.array(datax), np.array(datay)\n",
    "\n",
    "def read_images(base_directory):\n",
    "    \"\"\"\n",
    "    Reads all the alphabets from the base_directory\n",
    "    Uses multithreading to decrease the reading time drastically\n",
    "    \"\"\"\n",
    "    datax = []\n",
    "    datay = []\n",
    "    i = 0\n",
    "    for directory in os.listdir(base_directory):\n",
    "        result = read_alphabets( base_directory + '/' + directory + '/', directory)\n",
    "        datax.append(result[0])\n",
    "        datay.append(result[1])    \n",
    "        i +=1\n",
    "        if(i % 5 == 0):\n",
    "            print(i)\n",
    "            print(result[0].shape)\n",
    "    dataxn = np.concatenate(datax, axis=0)\n",
    "    datayn = np.concatenate(datay, axis=0)\n",
    "    del datax\n",
    "    del datay\n",
    "    return dataxn, datayn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sample(n_way, n_support, n_query, datax, datay):\n",
    "    \"\"\"\n",
    "    Picks random sample of size n_support+n_querry, for n_way classes\n",
    "    Args:\n",
    "      n_way (int): number of classes in a classification task\n",
    "      n_support (int): number of labeled examples per class in the support set\n",
    "      n_query (int): number of labeled examples per class in the query set\n",
    "      datax (np.array): dataset of images\n",
    "      datay (np.array): dataset of labels\n",
    "    Returns:\n",
    "      (dict) of:\n",
    "        (torch.Tensor): sample of images. Size (n_way, n_support+n_query, (dim))\n",
    "        (int): n_way\n",
    "        (int): n_support\n",
    "        (int): n_query\n",
    "    \"\"\"\n",
    "    sample = []\n",
    "    K = np.random.choice(np.unique(datay), n_way, replace=False)\n",
    "    \n",
    "    for cls in K:\n",
    "        datax_cls = datax[datay == cls]\n",
    "        perm = np.random.permutation(datax_cls)\n",
    "        sample_cls = perm[:(n_support+n_query)]\n",
    "        sample.append(sample_cls)\n",
    "    sample = np.array(sample)\n",
    "    sample = torch.from_numpy(sample).float()\n",
    "    sample = sample.permute(0,1,4,2,3)\n",
    "    return({\n",
    "      'images': sample,\n",
    "      'n_way': n_way,\n",
    "      'n_support': n_support,\n",
    "      'n_query': n_query\n",
    "      })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_dist(x, y):\n",
    "    \"\"\"\n",
    "    Computes euclidean distance btw x and y\n",
    "    Args:\n",
    "      x (torch.Tensor): shape (n, d). n usually n_way*n_query\n",
    "      y (torch.Tensor): shape (m, d). m usually n_way\n",
    "    Returns:\n",
    "      torch.Tensor: shape(n, m). For each query, the distances to each centroid\n",
    "    \"\"\"\n",
    "    n = x.size(0)\n",
    "    m = y.size(0)\n",
    "    d = x.size(1)\n",
    "    assert d == y.size(1)\n",
    "\n",
    "    x = x.unsqueeze(1).expand(n, m, d)\n",
    "    y = y.unsqueeze(0).expand(n, m, d)\n",
    "\n",
    "    return torch.pow(x - y, 2).sum(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "(3200, 28, 28, 3)\n",
      "10\n",
      "(2720, 28, 28, 3)\n",
      "15\n",
      "(1920, 28, 28, 3)\n",
      "20\n",
      "(3760, 28, 28, 3)\n",
      "25\n",
      "(2640, 28, 28, 3)\n",
      "30\n",
      "(4400, 28, 28, 3)\n",
      "Wall time: 38.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "trainx, trainy = read_images('images_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "(2080, 28, 28, 3)\n",
      "10\n",
      "(2080, 28, 28, 3)\n",
      "15\n",
      "(3680, 28, 28, 3)\n",
      "20\n",
      "(2080, 28, 28, 3)\n",
      "Wall time: 22.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "testx, testy = read_images('images_evaluation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((77120, 28, 28, 3), (77120,), (52720, 28, 28, 3), (52720,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainx.shape, trainy.shape, testx.shape, testy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_sample(sample):\n",
    "    \"\"\"\n",
    "    Displays sample in a grid\n",
    "    Args:\n",
    "      sample (torch.Tensor): sample of images to display\n",
    "    \"\"\"\n",
    "    #need 4D tensor to create grid, currently 5D\n",
    "    sample_4D = sample.view(sample.shape[0]*sample.shape[1],*sample.shape[2:])\n",
    "    #make a grid\n",
    "    out = torchvision.utils.make_grid(sample_4D, nrow=sample.shape[1])\n",
    "    plt.figure(figsize = (16,7))\n",
    "    plt.imshow(out.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_example = extract_sample(8, 5, 5, trainx, trainy)\n",
    "display_sample(sample_example['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Flatten, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "def load_protonet_conv(**kwargs):\n",
    "    \"\"\"\n",
    "    Loads the prototypical network model\n",
    "    Arg:\n",
    "      x_dim (tuple): dimension of input image\n",
    "      hid_dim (int): dimension of hidden layers in conv blocks\n",
    "      z_dim (int): dimension of embedded image\n",
    "    Returns:\n",
    "      Model (Class ProtoNet)\n",
    "    \"\"\"\n",
    "    x_dim = kwargs['x_dim']\n",
    "    hid_dim = kwargs['hid_dim']\n",
    "    z_dim = kwargs['z_dim']\n",
    "\n",
    "    def conv_block(in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "            )\n",
    "\n",
    "    encoder = nn.Sequential(\n",
    "    conv_block(x_dim[0], hid_dim),\n",
    "    conv_block(hid_dim, hid_dim),\n",
    "    conv_block(hid_dim, hid_dim),\n",
    "    conv_block(hid_dim, z_dim),\n",
    "    Flatten()\n",
    "    )\n",
    "\n",
    "    return ProtoNet(encoder)\n",
    "\n",
    "class ProtoNet(nn.Module):\n",
    "    def __init__(self, encoder):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            encoder : CNN encoding the images in sample\n",
    "            n_way (int): number of classes in a classification task\n",
    "            n_support (int): number of labeled examples per class in the support set\n",
    "            n_query (int): number of labeled examples per class in the query set\n",
    "        \"\"\"\n",
    "        super(ProtoNet, self).__init__()\n",
    "        self.encoder = encoder.cuda()\n",
    "\n",
    "    def set_forward_loss(self, sample):\n",
    "        \"\"\"\n",
    "        Computes loss, accuracy and output for classification task\n",
    "        Args:\n",
    "            sample (torch.Tensor): shape (n_way, n_support+n_query, (dim)) \n",
    "        Returns:\n",
    "            torch.Tensor: shape(2), loss, accuracy and y_hat\n",
    "        \"\"\"\n",
    "        sample_images = sample['images'].cuda()\n",
    "        n_way = sample['n_way']\n",
    "        n_support = sample['n_support']\n",
    "        n_query = sample['n_query']\n",
    "\n",
    "        x_support = sample_images[:, :n_support]\n",
    "        x_query = sample_images[:, n_support:]\n",
    "\n",
    "        #target indices are 0 ... n_way-1\n",
    "        target_inds = torch.arange(0, n_way).view(n_way, 1, 1).expand(n_way, n_query, 1).long()\n",
    "        target_inds = Variable(target_inds, requires_grad=False)\n",
    "        target_inds = target_inds.cuda()\n",
    "\n",
    "        #encode images of the support and the query set\n",
    "        x = torch.cat([x_support.contiguous().view(n_way * n_support, *x_support.size()[2:]),\n",
    "                       x_query.contiguous().view(n_way * n_query, *x_query.size()[2:])], 0)\n",
    "\n",
    "        z = self.encoder.forward(x)\n",
    "        z_dim = z.size(-1) #usually 64\n",
    "        z_proto = z[:n_way*n_support].view(n_way, n_support, z_dim).mean(1)\n",
    "        z_query = z[n_way*n_support:]\n",
    "\n",
    "        #compute distances\n",
    "        dists = euclidean_dist(z_query, z_proto)\n",
    "\n",
    "        #compute probabilities\n",
    "        log_p_y = F.log_softmax(-dists, dim=1).view(n_way, n_query, -1)\n",
    "\n",
    "        loss_val = -log_p_y.gather(2, target_inds).squeeze().view(-1).mean()\n",
    "        _, y_hat = log_p_y.max(2)\n",
    "        acc_val = torch.eq(y_hat, target_inds.squeeze()).float().mean()\n",
    "\n",
    "        return loss_val, {\n",
    "            'loss': loss_val.item(),\n",
    "            'acc': acc_val.item(),\n",
    "            'y_hat': y_hat\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Flatten, self).__init__()\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "def load_protonet_conv(**kwargs):\n",
    "    \"\"\"\n",
    "    Loads the prototypical network model\n",
    "    Arg:\n",
    "      x_dim (tuple): dimension of input image\n",
    "      hid_dim (int): dimension of hidden layers in conv blocks\n",
    "      z_dim (int): dimension of embedded image\n",
    "    Returns:\n",
    "      Model (Class ProtoNet)\n",
    "    \"\"\"\n",
    "    x_dim = kwargs['x_dim']\n",
    "    hid_dim = kwargs['hid_dim']\n",
    "    z_dim = kwargs['z_dim']\n",
    "\n",
    "    def conv_block(in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "            )\n",
    "\n",
    "    encoder = nn.Sequential(\n",
    "        conv_block(x_dim[0], hid_dim),\n",
    "        conv_block(hid_dim, hid_dim),\n",
    "        conv_block(hid_dim, hid_dim),\n",
    "        conv_block(hid_dim, z_dim),\n",
    "        Flatten()\n",
    "        )\n",
    "\n",
    "    return ProtoNet(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_dist(x, y):\n",
    "    \"\"\"\n",
    "    Computes euclidean distance btw x and y\n",
    "    Args:\n",
    "      x (torch.Tensor): shape (n, d). n usually n_way*n_query\n",
    "      y (torch.Tensor): shape (m, d). m usually n_way\n",
    "    Returns:\n",
    "      torch.Tensor: shape(n, m). For each query, the distances to each centroid\n",
    "    \"\"\"\n",
    "    n = x.size(0)\n",
    "    m = y.size(0)\n",
    "    d = x.size(1)\n",
    "    assert d == y.size(1)\n",
    "\n",
    "    x = x.unsqueeze(1).expand(n, m, d)\n",
    "    y = y.unsqueeze(0).expand(n, m, d)\n",
    "\n",
    "    return torch.pow(x - y, 2).sum(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "from tqdm import tnrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_x, train_y, n_way, n_support, n_query, max_epoch, epoch_size):\n",
    "    \"\"\"\n",
    "    Trains the protonet\n",
    "    Args:\n",
    "      model\n",
    "      optimizer\n",
    "      train_x (np.array): images of training set\n",
    "      train_y(np.array): labels of training set\n",
    "      n_way (int): number of classes in a classification task\n",
    "      n_support (int): number of labeled examples per class in the support set\n",
    "      n_query (int): number of labeled examples per class in the query set\n",
    "      max_epoch (int): max epochs to train on\n",
    "      epoch_size (int): episodes per epoch\n",
    "    \"\"\"\n",
    "    #divide the learning rate by 2 at each epoch, as suggested in paper\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.5, last_epoch=-1)\n",
    "    epoch = 0 #epochs done so far\n",
    "    stop = False #status to know when to stop\n",
    "\n",
    "    while epoch < max_epoch and not stop:\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "\n",
    "        for episode in tnrange(epoch_size, desc=\"Epoch {:d} train\".format(epoch+1)):\n",
    "            sample = extract_sample(n_way, n_support, n_query, train_x, train_y)\n",
    "            optimizer.zero_grad()\n",
    "            loss, output = model.set_forward_loss(sample)\n",
    "            running_loss += output['loss']\n",
    "            running_acc += output['acc']\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        epoch_loss = running_loss / epoch_size\n",
    "        epoch_acc = running_acc / epoch_size\n",
    "        print('Epoch {:d} -- Loss: {:.4f} Acc: {:.4f}'.format(epoch+1,epoch_loss, epoch_acc))\n",
    "        epoch += 1\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Challenger\\Anaconda3\\envs\\epytorch\\lib\\site-packages\\ipykernel_launcher.py:24: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "540ae3b1d3ff4fdcb6e3806065a698dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1 train:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 -- Loss: 0.0773 Acc: 0.9759\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35d9bcf77d714f4fb68017252fe1066e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2 train:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 -- Loss: 0.0291 Acc: 0.9897\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c2b38527b3f4e78a00a1f3b40ab3caf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3 train:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 -- Loss: 0.0219 Acc: 0.9921\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d26125595bb54078a7e9e75ef784a205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4 train:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 -- Loss: 0.0179 Acc: 0.9934\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2992c69205394b079c905be8b91b306e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5 train:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 -- Loss: 0.0152 Acc: 0.9942\n",
      "Wall time: 48min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = load_protonet_conv(\n",
    "    x_dim=(3,28,28),\n",
    "    hid_dim=64,\n",
    "    z_dim=64,\n",
    "    )\n",
    "model = model.to(ctx)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "n_way = 60\n",
    "n_support = 5\n",
    "n_query = 5\n",
    "\n",
    "train_x = trainx\n",
    "train_y = trainy\n",
    "\n",
    "max_epoch = 5\n",
    "epoch_size = 2000\n",
    "\n",
    "train(model, optimizer, train_x, train_y, n_way, n_support, n_query, max_epoch, epoch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_x, test_y, n_way, n_support, n_query, test_episode):\n",
    "    \"\"\"\n",
    "    Tests the protonet\n",
    "    Args:\n",
    "      model: trained model\n",
    "      test_x (np.array): images of testing set\n",
    "      test_y (np.array): labels of testing set\n",
    "      n_way (int): number of classes in a classification task\n",
    "      n_support (int): number of labeled examples per class in the support set\n",
    "      n_query (int): number of labeled examples per class in the query set\n",
    "      test_episode (int): number of episodes to test on\n",
    "    \"\"\"\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    for episode in tnrange(test_episode):\n",
    "        sample = extract_sample(n_way, n_support, n_query, test_x, test_y)\n",
    "        loss, output = model.set_forward_loss(sample)\n",
    "        running_loss += output['loss']\n",
    "        running_acc += output['acc']\n",
    "    avg_loss = running_loss / test_episode\n",
    "    avg_acc = running_acc / test_episode\n",
    "    print('Test results -- Loss: {:.4f} Acc: {:.4f}'.format(avg_loss, avg_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Challenger\\Anaconda3\\envs\\epytorch\\lib\\site-packages\\ipykernel_launcher.py:15: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4a65bc62bf84b4ab286127d23b32fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results -- Loss: 0.0142 Acc: 0.9979\n"
     ]
    }
   ],
   "source": [
    "n_way = 5\n",
    "n_support = 5\n",
    "n_query = 5\n",
    "\n",
    "test_x = testx\n",
    "test_y = testy\n",
    "\n",
    "test_episode = 1000\n",
    "\n",
    "test(model, test_x, test_y, n_way, n_support, n_query, test_episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_sample = extract_sample(n_way, n_support, n_query, test_x, test_y)\n",
    "display_sample(my_sample['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_loss, my_output = model.set_forward_loss(my_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 1.190578768728301e-05, 'acc': 1.0, 'y_hat': tensor([[0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [2, 2, 2, 2, 2],\n",
       "         [3, 3, 3, 3, 3],\n",
       "         [4, 4, 4, 4, 4]], device='cuda:0')}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
